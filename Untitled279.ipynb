{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a676d4bd-c15a-4c32-8e0b-f48293d29f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_attributes: Index(['City', 'Country', 'Latitude', 'Longitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"city_attributes:\", city.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "296f9c16-f03d-4028-a8ea-ad4defd59a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Final merged dataset: (1629108, 11)\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "32583/32583 [==============================] - 79s 2ms/step - loss: 0.8391 - accuracy: 0.7730 - val_loss: 0.8325 - val_accuracy: 0.7720\n",
      "Epoch 2/20\n",
      "32583/32583 [==============================] - 77s 2ms/step - loss: 0.8295 - accuracy: 0.7730 - val_loss: 0.8324 - val_accuracy: 0.7720\n",
      "Epoch 3/20\n",
      "32583/32583 [==============================] - 746s 23ms/step - loss: 0.8290 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 4/20\n",
      "32583/32583 [==============================] - 78s 2ms/step - loss: 0.8288 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 5/20\n",
      "32583/32583 [==============================] - 80s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 6/20\n",
      "32583/32583 [==============================] - 80s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 7/20\n",
      "32583/32583 [==============================] - 80s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8324 - val_accuracy: 0.7720\n",
      "Epoch 8/20\n",
      "32583/32583 [==============================] - 79s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 9/20\n",
      "32583/32583 [==============================] - 79s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 10/20\n",
      "32583/32583 [==============================] - 78s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 11/20\n",
      "32583/32583 [==============================] - 64s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 12/20\n",
      "32583/32583 [==============================] - 64s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 13/20\n",
      "32583/32583 [==============================] - 66s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 14/20\n",
      "32583/32583 [==============================] - 71s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 15/20\n",
      "32583/32583 [==============================] - 65s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 16/20\n",
      "32583/32583 [==============================] - 66s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 17/20\n",
      "32583/32583 [==============================] - 68s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 18/20\n",
      "32583/32583 [==============================] - 63s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "Epoch 19/20\n",
      "32583/32583 [==============================] - 70s 2ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8324 - val_accuracy: 0.7720\n",
      "Epoch 20/20\n",
      "32583/32583 [==============================] - 427s 13ms/step - loss: 0.8287 - accuracy: 0.7730 - val_loss: 0.8323 - val_accuracy: 0.7720\n",
      "10182/10182 [==============================] - 12s 1ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87    251956\n",
      "           1       0.00      0.00      0.00      3174\n",
      "           2       0.00      0.00      0.00      4808\n",
      "           3       0.00      0.00      0.00     19839\n",
      "           4       0.00      0.00      0.00     39630\n",
      "           5       0.00      0.00      0.00       419\n",
      "           6       0.00      0.00      0.00      4341\n",
      "           7       0.00      0.00      0.00      1655\n",
      "\n",
      "    accuracy                           0.77    325822\n",
      "   macro avg       0.10      0.12      0.11    325822\n",
      "weighted avg       0.60      0.77      0.67    325822\n",
      "\n",
      "Accuracy: 0.7732933933251899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Method `model.to_yaml()` has been removed due to security risk of arbitrary code execution. Please use `model.to_json()` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 149\u001b[39m\n\u001b[32m    143\u001b[39m     json.dump({\n\u001b[32m    144\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(acc),\n\u001b[32m    145\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mlist\u001b[39m(label_encoder.classes_)\n\u001b[32m    146\u001b[39m     }, f, indent=\u001b[32m4\u001b[39m)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(BASE, \u001b[33m\"\u001b[39m\u001b[33mfog_model.yaml\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     f.write(\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    151\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸŽ‰ ALL FILES SAVED SUCCESSFULLY!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3405\u001b[39m, in \u001b[36mModel.to_yaml\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   3382\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_yaml\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m   3383\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns a yaml string containing the network configuration.\u001b[39;00m\n\u001b[32m   3384\u001b[39m \n\u001b[32m   3385\u001b[39m \u001b[33;03m    Note: Since TF 2.6, this method is no longer supported and will raise a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3403\u001b[39m \u001b[33;03m        RuntimeError: announces that the method poses a security risk\u001b[39;00m\n\u001b[32m   3404\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   3406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMethod `model.to_yaml()` has been removed due to security risk of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3407\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33marbitrary code execution. Please use `model.to_json()` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3408\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Method `model.to_yaml()` has been removed due to security risk of arbitrary code execution. Please use `model.to_json()` instead."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pickle, json, yaml\n",
    "\n",
    "# ================================================================\n",
    "#  PATHS\n",
    "# ================================================================\n",
    "BASE = r\"C:\\Users\\NXTWAVE\\Downloads\\Fog Density & Visibility Prediction System\"\n",
    "\n",
    "hum = pd.read_csv(os.path.join(BASE, r\"archive (1)\\humidity.csv\"))\n",
    "pres = pd.read_csv(os.path.join(BASE, r\"archive (1)\\pressure.csv\"))\n",
    "temp = pd.read_csv(os.path.join(BASE, r\"archive (1)\\temperature.csv\"))\n",
    "weat = pd.read_csv(os.path.join(BASE, r\"archive (1)\\weather_description.csv\"))\n",
    "wdir = pd.read_csv(os.path.join(BASE, r\"archive (1)\\wind_direction.csv\"))\n",
    "wspd = pd.read_csv(os.path.join(BASE, r\"archive (1)\\wind_speed.csv\"))\n",
    "city = pd.read_csv(os.path.join(BASE, r\"archive (1)\\city_attributes.csv\"))\n",
    "\n",
    "# ================================================================\n",
    "#  FIX CITY COLUMN NAME\n",
    "# ================================================================\n",
    "city.rename(columns={\"City\": \"city\"}, inplace=True)\n",
    "\n",
    "# ================================================================\n",
    "#  CONVERT WIDE â†’ LONG FOR WEATHER FILES\n",
    "# ================================================================\n",
    "def melt_df(df, var_name):\n",
    "    return df.melt(id_vars=[\"datetime\"], var_name=\"city\", value_name=var_name)\n",
    "\n",
    "hum = melt_df(hum, \"humidity\")\n",
    "pres = melt_df(pres, \"pressure\")\n",
    "temp = melt_df(temp, \"temperature\")\n",
    "weat = melt_df(weat, \"weather_description\")\n",
    "wdir = melt_df(wdir, \"wind_direction\")\n",
    "wspd = melt_df(wspd, \"wind_speed\")\n",
    "\n",
    "# ================================================================\n",
    "#  MERGE ALL FILES\n",
    "# ================================================================\n",
    "df = hum.merge(pres, on=[\"datetime\", \"city\"])\n",
    "df = df.merge(temp, on=[\"datetime\", \"city\"])\n",
    "df = df.merge(weat, on=[\"datetime\", \"city\"])\n",
    "df = df.merge(wdir, on=[\"datetime\", \"city\"])\n",
    "df = df.merge(wspd, on=[\"datetime\", \"city\"])\n",
    "df = df.merge(city, on=\"city\")\n",
    "\n",
    "print(\"[INFO] Final merged dataset:\", df.shape)\n",
    "\n",
    "# ================================================================\n",
    "#  CREATE FOG LABEL FROM WEATHER DESCRIPTION\n",
    "# ================================================================\n",
    "fog_keywords = {\n",
    "    \"fog\": \"fog\",\n",
    "    \"mist\": \"mist\",\n",
    "    \"haze\": \"haze\",\n",
    "    \"smoke\": \"smoke\",\n",
    "    \"rain\": \"rain\",\n",
    "    \"snow\": \"snow\",\n",
    "    \"thunderstorm\": \"storm\"\n",
    "}\n",
    "\n",
    "def categorize(desc):\n",
    "    d = str(desc).lower()\n",
    "    for k,v in fog_keywords.items():\n",
    "        if k in d:\n",
    "            return v\n",
    "    return \"clear\"\n",
    "\n",
    "df[\"fog_label\"] = df[\"weather_description\"].apply(categorize)\n",
    "\n",
    "# ================================================================\n",
    "#  FEATURES + LABELS\n",
    "# ================================================================\n",
    "X = df[[\"humidity\", \"pressure\", \"temperature\", \"wind_direction\", \"wind_speed\"]]\n",
    "y = df[\"fog_label\"]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_enc = label_encoder.fit_transform(y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Save scaler\n",
    "with open(os.path.join(BASE, \"scaler.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_enc, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "#  MODEL ARCHITECTURE\n",
    "# ================================================================\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(np.unique(y_enc)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "#  EVALUATION\n",
    "# ================================================================\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "# ================================================================\n",
    "#  SAVE OUTPUT FILES\n",
    "# ================================================================\n",
    "model.save(os.path.join(BASE, \"fog_model.h5\"))\n",
    "\n",
    "with open(os.path.join(BASE, \"fog_model.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"label_encoder\": label_encoder,\n",
    "        \"weights\": model.get_weights()\n",
    "    }, f)\n",
    "\n",
    "with open(os.path.join(BASE, \"fog_model.json\"), \"w\") as f:\n",
    "    json.dump({\n",
    "        \"accuracy\": float(acc),\n",
    "        \"labels\": list(label_encoder.classes_)\n",
    "    }, f, indent=4)\n",
    "\n",
    "with open(os.path.join(BASE, \"fog_model.yaml\"), \"w\") as f:\n",
    "    f.write(model.to_yaml())\n",
    "\n",
    "print(\"\\nðŸŽ‰ ALL FILES SAVED SUCCESSFULLY!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0fdc1b-074a-42d8-bbb7-dbfe16a91083",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
